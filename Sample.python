from nltk.corpus import stopwords
from nltk.tokenize import sent_tokenize, word_tokenize

inputFile="resources/aptavani-09.txt"
wordsDict={}
stop_words = set(stopwords.words('english'))

with open(inputFile, 'r') as input:
    for line in input:
        line = line.split(" ")
        for word in line:
            word = word.lower()
            word = word.strip("\n")
            word = word.strip(":")
            word = word.strip(",")
            word = word.strip("'")
            word = word.strip("?")
            word = word.strip(".")
            word = word.strip(" ")
            word = word.strip("")
            if word not in stop_words:
                if word in wordsDict:
                    wordsDict[word]+=1
                else:
                    wordsDict[word]=1

res = list(sorted(wordsDict, key=wordsDict.__getitem__, reverse=True))
for word in res:
    print (word,wordsDict[word])